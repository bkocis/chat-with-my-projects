#!/usr/bin/env python3
"""
Query utility for preprocessed repository data.

This script provides convenient functions to query and analyze the preprocessed
repository data generated by data_preprocessor.py.
"""

import json
import os
from pathlib import Path
from typing import List, Dict, Any, Optional
from collections import Counter


class RepositoryDataQuery:
    """Query interface for preprocessed repository data."""
    
    def __init__(self, data_dir: str = 'mcp-resources'):
        self.data_dir = Path(data_dir)
        self.summary_file = self.data_dir / 'repositories_summary.json'
        self.data_file = self.data_dir / 'repositories_data.json'
        self.readme_index_file = self.data_dir / 'readme_index.json'
        self.repos_dir = self.data_dir / 'repositories'
        
        # Load summary data
        self.summary = self._load_json(self.summary_file)
        self.readme_index = self._load_json(self.readme_index_file)
    
    def _load_json(self, file_path: Path) -> dict:
        """Load JSON file with error handling."""
        try:
            if file_path.exists():
                with open(file_path, 'r') as f:
                    return json.load(f)
            return {}
        except Exception as e:
            print(f"Error loading {file_path}: {e}")
            return {}
    
    def get_repository(self, repo_name: str) -> Optional[Dict[str, Any]]:
        """Get detailed data for a specific repository."""
        repo_file = self.repos_dir / f"{repo_name}.json"
        return self._load_json(repo_file)
    
    def list_repositories(self) -> List[str]:
        """Get list of all repository names."""
        return self.summary.get('repository_list', [])
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """Get summary statistics."""
        return self.summary.get('summary', {})
    
    def find_repositories_by_language(self, language: str) -> List[str]:
        """Find repositories that use a specific programming language."""
        matching_repos = []
        
        for repo_name in self.list_repositories():
            repo_data = self.get_repository(repo_name)
            if repo_data:
                languages = repo_data.get('file_structure', {}).get('languages', {})
                if language in languages:
                    matching_repos.append(repo_name)
        
        return matching_repos
    
    def find_repositories_by_framework(self, framework: str) -> List[str]:
        """Find repositories that use a specific framework."""
        matching_repos = []
        
        for repo_name in self.list_repositories():
            repo_data = self.get_repository(repo_name)
            if repo_data:
                frameworks = repo_data.get('technologies', {}).get('frameworks', [])
                if framework in frameworks:
                    matching_repos.append(repo_name)
        
        return matching_repos
    
    def search_readmes(self, search_term: str, case_sensitive: bool = False) -> List[Dict[str, Any]]:
        """Search for a term in README files."""
        matching_readmes = []
        
        if not self.readme_index:
            return matching_readmes
        
        search_term_processed = search_term if case_sensitive else search_term.lower()
        
        for readme in self.readme_index.get('readmes', []):
            content_to_search = readme.get('summary', '')
            if not case_sensitive:
                content_to_search = content_to_search.lower()
            
            if search_term_processed in content_to_search:
                matching_readmes.append(readme)
        
        return matching_readmes
    
    def get_largest_repositories(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Get repositories sorted by total size."""
        repo_sizes = []
        
        for repo_name in self.list_repositories():
            repo_data = self.get_repository(repo_name)
            if repo_data:
                total_size = repo_data.get('file_structure', {}).get('total_size', 0)
                repo_sizes.append({
                    'name': repo_name,
                    'size': total_size,
                    'size_mb': total_size / (1024 * 1024)
                })
        
        repo_sizes.sort(key=lambda x: x['size'], reverse=True)
        return repo_sizes[:limit]
    
    def get_most_active_repositories(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Get repositories with most recent commits (requires git info)."""
        repo_activity = []
        
        for repo_name in self.list_repositories():
            repo_data = self.get_repository(repo_name)
            if repo_data and repo_data.get('git_info', {}).get('last_commit'):
                last_commit = repo_data['git_info']['last_commit']
                repo_activity.append({
                    'name': repo_name,
                    'last_commit_date': last_commit.get('date', ''),
                    'last_commit_message': last_commit.get('message', '')
                })
        
        # Sort by date (this is a simple string sort, may not be perfect for all date formats)
        repo_activity.sort(key=lambda x: x['last_commit_date'], reverse=True)
        return repo_activity[:limit]
    
    def get_technology_distribution(self) -> Dict[str, Dict[str, int]]:
        """Get distribution of technologies across all repositories."""
        tech_stats = {
            'languages': Counter(),
            'frameworks': Counter(),
            'tools': Counter(),
            'databases': Counter()
        }
        
        for repo_name in self.list_repositories():
            repo_data = self.get_repository(repo_name)
            if repo_data:
                # Count languages
                languages = repo_data.get('file_structure', {}).get('languages', {})
                for lang, count in languages.items():
                    tech_stats['languages'][lang] += 1  # Count repos, not files
                
                # Count technologies
                technologies = repo_data.get('technologies', {})
                for tech_type in ['frameworks', 'tools', 'databases']:
                    for tech in technologies.get(tech_type, []):
                        tech_stats[tech_type][tech] += 1
        
        return {k: dict(v) for k, v in tech_stats.items()}
    
    def generate_report(self) -> str:
        """Generate a comprehensive text report."""
        report_lines = []
        
        # Header
        report_lines.append("Repository Analysis Report")
        report_lines.append("=" * 50)
        report_lines.append("")
        
        # Basic stats
        if self.summary:
            metadata = self.summary.get('metadata', {})
            summary_stats = self.summary.get('summary', {})
            
            report_lines.append("Overview:")
            report_lines.append(f"  Total repositories: {metadata.get('total_repositories', 'N/A')}")
            report_lines.append(f"  Total files: {summary_stats.get('total_files', 0):,}")
            report_lines.append(f"  Total size: {summary_stats.get('total_size', 0) / (1024*1024):.1f} MB")
            report_lines.append(f"  Last updated: {metadata.get('processing_timestamp', 'N/A')}")
            report_lines.append("")
            
            # Top languages
            languages = summary_stats.get('languages', {})
            if languages:
                report_lines.append("Top Programming Languages:")
                for lang, count in Counter(languages).most_common(10):
                    report_lines.append(f"  {lang}: {count} repositories")
                report_lines.append("")
            
            # Top frameworks
            frameworks = summary_stats.get('frameworks', {})
            if frameworks:
                report_lines.append("Top Frameworks:")
                for framework, count in Counter(frameworks).most_common(10):
                    report_lines.append(f"  {framework}: {count} repositories")
                report_lines.append("")
        
        # Largest repositories
        largest_repos = self.get_largest_repositories(5)
        if largest_repos:
            report_lines.append("Largest Repositories:")
            for repo in largest_repos:
                report_lines.append(f"  {repo['name']}: {repo['size_mb']:.1f} MB")
            report_lines.append("")
        
        # Recent activity
        active_repos = self.get_most_active_repositories(5)
        if active_repos:
            report_lines.append("Most Recently Updated:")
            for repo in active_repos:
                report_lines.append(f"  {repo['name']}: {repo['last_commit_date']}")
            report_lines.append("")
        
        return "\n".join(report_lines)


def main():
    """Command-line interface for querying repository data."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Query preprocessed repository data')
    parser.add_argument('--data-dir', default='mcp-resources', help='Data directory')
    parser.add_argument('--report', action='store_true', help='Generate full report')
    parser.add_argument('--list-repos', action='store_true', help='List all repositories')
    parser.add_argument('--language', help='Find repos using specific language')
    parser.add_argument('--framework', help='Find repos using specific framework')
    parser.add_argument('--search-readme', help='Search README files')
    parser.add_argument('--largest', type=int, default=10, help='Show N largest repos')
    parser.add_argument('--tech-stats', action='store_true', help='Show technology statistics')
    
    args = parser.parse_args()
    
    # Initialize query interface
    query = RepositoryDataQuery(args.data_dir)
    
    if args.report:
        print(query.generate_report())
    
    elif args.list_repos:
        repos = query.list_repositories()
        print(f"Found {len(repos)} repositories:")
        for repo in sorted(repos):
            print(f"  - {repo}")
    
    elif args.language:
        repos = query.find_repositories_by_language(args.language)
        print(f"Repositories using {args.language}:")
        for repo in repos:
            print(f"  - {repo}")
    
    elif args.framework:
        repos = query.find_repositories_by_framework(args.framework)
        print(f"Repositories using {args.framework}:")
        for repo in repos:
            print(f"  - {repo}")
    
    elif args.search_readme:
        matches = query.search_readmes(args.search_readme)
        print(f"README files containing '{args.search_readme}':")
        for match in matches:
            print(f"  - {match['repository']}: {match['file_path']}")
    
    elif args.tech_stats:
        tech_dist = query.get_technology_distribution()
        
        for tech_type, stats in tech_dist.items():
            if stats:
                print(f"\n{tech_type.title()}:")
                for tech, count in Counter(stats).most_common(10):
                    print(f"  {tech}: {count} repositories")
    
    else:
        # Default: show summary
        stats = query.get_summary_stats()
        if stats:
            print("Repository Summary:")
            print(f"  Total files: {stats.get('total_files', 0):,}")
            print(f"  Total size: {stats.get('total_size', 0) / (1024*1024):.1f} MB")
            
            languages = stats.get('languages', {})
            if languages:
                print(f"  Top languages: {dict(Counter(languages).most_common(5))}")
        else:
            print("No data found. Run preprocessing first.")


if __name__ == '__main__':
    main()